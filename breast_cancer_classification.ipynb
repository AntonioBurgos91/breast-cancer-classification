{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aaec1a-6ecb-41a7-a939-ae2c82cad070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURACIÓN DEL ENTORNO E IMPORTACIÓN DE LIBRERÍAS\n",
    "# -------------------------------------------------------------\n",
    "# Esta celda se encarga de importar todas las librerías necesarias para el proyecto.\n",
    "# Es una buena práctica agrupar todas las importaciones al inicio del notebook.\n",
    "\n",
    "# Para manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Para visualización de datos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Para la adquisición de datos desde Kaggle\n",
    "import kagglehub\n",
    "import os # Para interactuar con el sistema operativo (manejo de archivos y rutas)\n",
    "import zipfile # Para descomprimir archivos .zip\n",
    "\n",
    "# Para preprocesamiento y modelado\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer # Para aplicar diferentes transformaciones a diferentes columnas\n",
    "from sklearn.pipeline import Pipeline # Para encadenar pasos de preprocesamiento y modelado\n",
    "\n",
    "# Modelos de Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb # Para XGBoost\n",
    "\n",
    "# Métricas de evaluación\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, ConfusionMatrixDisplay, precision_recall_curve\n",
    "\n",
    "# Para manejo de desequilibrio de clases (opcional, pero bueno tenerlo)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Para interpretación de modelos (opcional)\n",
    "# import shap # Descomentar si se va a usar SHAP\n",
    "\n",
    "# Para ignorar advertencias (usar con precaución)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraciones para mejorar la visualización de los gráficos\n",
    "plt.style.use('seaborn-v0_8-whitegrid') # Estilo de los gráficos\n",
    "plt.rcParams['figure.figsize'] = (12, 7) # Tamaño por defecto de las figuras\n",
    "plt.rcParams['font.size'] = 12 # Tamaño por defecto de la fuente\n",
    "\n",
    "print(\"Librerías importadas y configuración inicial lista.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83be3587-12f0-4588-834b-2ab9d6a956fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADQUISICIÓN DE DATOS\n",
    "# ---------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "from io import StringIO\n",
    "import zipfile\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Opción 1: Usar el dataset incorporado en scikit-learn\n",
    "print(\"OPCIÓN 1: Cargando dataset de cáncer de mama desde scikit-learn...\")\n",
    "try:\n",
    "    # Cargar el dataset integrado en scikit-learn\n",
    "    breast_cancer = load_breast_cancer()\n",
    "    \n",
    "    # Crear DataFrame con los datos y características\n",
    "    df = pd.DataFrame(data=breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "    \n",
    "    # Añadir la columna objetivo (0=maligno, 1=benigno)\n",
    "    df['diagnosis'] = breast_cancer.target\n",
    "    \n",
    "    # Convertir los valores numéricos a categorías de texto para mayor claridad\n",
    "    df['diagnosis'] = df['diagnosis'].map({0: 'malignant', 1: 'benign'})\n",
    "    \n",
    "    # Guardar una copia del dataframe original\n",
    "    df_original = df.copy()\n",
    "    \n",
    "    print(\"Dataset de scikit-learn cargado con éxito.\")\n",
    "    print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "    \n",
    "    # Mostrar primeras filas del dataset\n",
    "    print(\"\\nPrimeras filas del dataset:\")\n",
    "    print(df.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error con scikit-learn: {e}\")\n",
    "\n",
    "# Opción 2: Descarga directa desde URL (GitHub u otra fuente confiable)\n",
    "print(\"\\n\\nOPCIÓN 2: Intentando descarga directa desde GitHub...\")\n",
    "try:\n",
    "    # URL de la fuente - usando una URL de ejemplo del dataset en GitHub\n",
    "    url = \"https://raw.githubusercontent.com/reihanenamdari/breast_cancer/master/data.csv\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Leer el contenido CSV directamente desde la respuesta\n",
    "        s = StringIO(response.text)\n",
    "        df2 = pd.read_csv(s)\n",
    "        df2_original = df2.copy()\n",
    "        \n",
    "        print(\"Dataset descargado exitosamente desde URL directa.\")\n",
    "        print(f\"Dimensiones del dataset: {df2.shape}\")\n",
    "        \n",
    "        # Mostrar primeras filas del dataset\n",
    "        print(\"\\nPrimeras filas del dataset:\")\n",
    "        print(df2.head())\n",
    "        \n",
    "        # Si el dataset de sklearn no se cargó, usar este\n",
    "        if 'df' not in locals() or df.empty:\n",
    "            df = df2\n",
    "            df_original = df2_original\n",
    "            print(\"\\nUsando dataset de URL como dataset principal.\")\n",
    "    else:\n",
    "        print(f\"Error al descargar: Código de estado {response.status_code}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error con descarga directa: {e}\")\n",
    "\n",
    "# Opción 3: Crear conjunto de datos sintético similar si todas las opciones anteriores fallan\n",
    "if 'df' not in locals() or df.empty:\n",
    "    print(\"\\n\\nOPCIÓN 3: Creando dataset sintético como último recurso...\")\n",
    "    try:\n",
    "        # Generar un dataset sintético basado en la estructura conocida del dataset de cáncer de mama\n",
    "        np.random.seed(42)  # Para reproducibilidad\n",
    "        \n",
    "        # Número de muestras\n",
    "        n_samples = 569\n",
    "        \n",
    "        # Crear características con distribuciones similares al dataset real\n",
    "        features = [\n",
    "            'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', \n",
    "            'smoothness_mean', 'compactness_mean', 'concavity_mean', \n",
    "            'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "            'radius_se', 'texture_se', 'perimeter_se', 'area_se', \n",
    "            'smoothness_se', 'compactness_se', 'concavity_se', \n",
    "            'concave points_se', 'symmetry_se', 'fractal_dimension_se',\n",
    "            'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', \n",
    "            'smoothness_worst', 'compactness_worst', 'concavity_worst', \n",
    "            'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst'\n",
    "        ]\n",
    "        \n",
    "        # Diccionario para almacenar los datos generados\n",
    "        data = {}\n",
    "        \n",
    "        # Generar datos para cada característica con rangos plausibles\n",
    "        for feature in features:\n",
    "            if 'radius' in feature:\n",
    "                data[feature] = np.random.uniform(6, 28, n_samples)\n",
    "            elif 'texture' in feature:\n",
    "                data[feature] = np.random.uniform(9, 40, n_samples)\n",
    "            elif 'perimeter' in feature:\n",
    "                data[feature] = np.random.uniform(40, 190, n_samples)\n",
    "            elif 'area' in feature:\n",
    "                data[feature] = np.random.uniform(140, 2500, n_samples)\n",
    "            elif 'smoothness' in feature:\n",
    "                data[feature] = np.random.uniform(0.05, 0.16, n_samples)\n",
    "            elif 'compactness' in feature:\n",
    "                data[feature] = np.random.uniform(0.02, 0.35, n_samples)\n",
    "            elif 'concavity' in feature:\n",
    "                data[feature] = np.random.uniform(0, 0.5, n_samples)\n",
    "            elif 'concave points' in feature:\n",
    "                data[feature] = np.random.uniform(0, 0.2, n_samples)\n",
    "            elif 'symmetry' in feature:\n",
    "                data[feature] = np.random.uniform(0.1, 0.3, n_samples)\n",
    "            elif 'fractal' in feature:\n",
    "                data[feature] = np.random.uniform(0.05, 0.1, n_samples)\n",
    "        \n",
    "        # Crear el DataFrame con las características\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Generar etiquetas diagnósticas (aproximadamente 37% malignas, 63% benignas)\n",
    "        diagnoses = np.random.choice(['malignant', 'benign'], size=n_samples, p=[0.37, 0.63])\n",
    "        df['diagnosis'] = diagnoses\n",
    "        \n",
    "        # Guardar copia del original\n",
    "        df_original = df.copy()\n",
    "        \n",
    "        print(\"Dataset sintético creado con éxito.\")\n",
    "        print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "        \n",
    "        # Mostrar primeras filas del dataset\n",
    "        print(\"\\nPrimeras filas del dataset:\")\n",
    "        print(df.head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al crear dataset sintético: {e}\")\n",
    "\n",
    "# Comprobar si tenemos un dataset válido\n",
    "if 'df' in locals() and not df.empty:\n",
    "    print(\"\\n\\nResumen del dataset final:\")\n",
    "    print(f\"Número de filas: {df.shape[0]}\")\n",
    "    print(f\"Número de columnas: {df.shape[1]}\")\n",
    "    print(\"\\nInformación del dataset:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nEstadísticas descriptivas:\")\n",
    "    print(df.describe())\n",
    "    print(\"\\nDistribución de diagnósticos:\")\n",
    "    print(df['diagnosis'].value_counts())\n",
    "else:\n",
    "    print(\"\\n\\nNo se pudo obtener un dataset válido. Por favor, verifica tu conexión a internet o considera descargar manualmente el dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35373c7a-dbe4-4ca7-b7c4-167351f2415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECCIÓN INICIAL DE DATOS\n",
    "# -----------------------------------\n",
    "# Con los datos ya cargados en nuestro DataFrame `df`,\n",
    "# es momento de realizar una inspección básica para entender su estructura y contenido.\n",
    "# Esto incluye verificar dimensiones, tipos de datos y visualizar algunas filas.\n",
    "\n",
    "# `display` es preferible a `print` para DataFrames en entornos como Jupyter Notebooks,\n",
    "# ya que ofrece una representación HTML más rica.\n",
    "\n",
    "if 'df' in locals() and not df.empty:\n",
    "    print(\"--- Iniciando Inspección General del Dataset ---\")\n",
    "    \n",
    "    # Confirmamos las dimensiones: número de filas (observaciones) y columnas (variables).\n",
    "    print(f\"\\nDimensiones del Dataset: {df.shape[0]} filas x {df.shape[1]} columnas.\")\n",
    "\n",
    "    # `df.info()` es muy útil: nos da un resumen conciso de cada columna,\n",
    "    # su tipo de dato (Dtype) y el número de valores no nulos.\n",
    "    # Esto ayuda a identificar rápidamente si hay tipos de datos inesperados o muchos faltantes.\n",
    "    print(\"\\nResumen de Información de las Columnas (df.info()):\")\n",
    "    df.info()\n",
    "\n",
    "    # Visualizar las primeras filas nos da una idea tangible de los datos.\n",
    "    print(\"\\nPrimeras 5 filas del Dataset (df.head()):\")\n",
    "    display(df.head())\n",
    "\n",
    "    # Visualizar las últimas filas también puede ser útil para detectar patrones o problemas al final del dataset.\n",
    "    print(\"\\nÚltimas 5 filas del Dataset (df.tail()):\")\n",
    "    display(df.tail())\n",
    "    \n",
    "    # Obtener una lista de todos los nombres de las columnas es útil para referencia futura\n",
    "    # y para verificar que la carga se hizo correctamente.\n",
    "    print(\"\\nNombres de todas las Columnas:\")\n",
    "    print(list(df.columns))\n",
    "\n",
    "else:\n",
    "    # Mensaje de error si el DataFrame no está disponible.\n",
    "    print(\"El DataFrame `df` parece estar vacío o no definido. No se puede realizar la inspección.\")\n",
    "    print(\"Por favor, asegúrese de que la Celda 2 (Adquisición de Datos) se haya ejecutado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d62ba-dacb-40fa-ac0f-e645d9882f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESTADÍSTICAS DESCRIPTIVAS Y VALORES NULOS/DUPLICADOS\n",
    "# -----------------------------------------------------------\n",
    "# Profundizamos en la inspección con estadísticas descriptivas más completas\n",
    "# y una verificación exhaustiva de la presencia de valores ausentes (nulos)\n",
    "# y filas duplicadas, aspectos críticos para la calidad de los datos.\n",
    "\n",
    "if 'df' in locals() and not df.empty:\n",
    "    # `df.describe(include='all')` nos da estadísticas para todas las columnas,\n",
    "    # incluyendo las no numéricas (como nuestra columna 'diagnosis').\n",
    "    # Para columnas numéricas: conteo, media, desviación estándar, mínimo, percentiles (25%, 50%, 75%) y máximo.\n",
    "    # Para columnas categóricas/texto: conteo, número de valores únicos, el valor más frecuente (top) y su frecuencia (freq).\n",
    "    print(\"\\n--- Estadísticas Descriptivas Completas (df.describe(include='all')) ---\")\n",
    "    display(df.describe(include='all'))\n",
    "\n",
    "    # Verificación detallada de valores nulos.\n",
    "    print(\"\\n--- Análisis de Valores Nulos por Columna ---\")\n",
    "    null_counts_per_column = df.isnull().sum()\n",
    "    null_percentage_per_column = (df.isnull().sum() / len(df)) * 100\n",
    "    \n",
    "    # Creamos un DataFrame para presentar esta información de forma clara.\n",
    "    null_analysis_df = pd.DataFrame({\n",
    "        'Número de Nulos': null_counts_per_column,\n",
    "        'Porcentaje de Nulos (%)': null_percentage_per_column\n",
    "    })\n",
    "    \n",
    "    # Mostramos solo las columnas que efectivamente tienen valores nulos, ordenadas por porcentaje.\n",
    "    missing_values_summary_df = null_analysis_df[null_analysis_df['Número de Nulos'] > 0].sort_values(\n",
    "        by='Porcentaje de Nulos (%)', ascending=False\n",
    "    )\n",
    "    \n",
    "    if not missing_values_summary_df.empty:\n",
    "        print(\"Se han detectado valores nulos en las siguientes columnas:\")\n",
    "        display(missing_values_summary_df)\n",
    "    elif null_counts_per_column.sum() == 0: # Doble verificación por si acaso\n",
    "        print(\"¡Excelente! No se han encontrado valores nulos en ninguna columna del dataset.\")\n",
    "    else:\n",
    "        # Este caso sería raro si el anterior se cumple, pero es una salvaguarda.\n",
    "        print(f\"No hay columnas con un conteo individual de nulos > 0, pero el total de nulos es: {null_counts_per_column.sum()}\")\n",
    "\n",
    "\n",
    "    # Verificación de filas completamente duplicadas.\n",
    "    print(\"\\n--- Análisis de Filas Duplicadas ---\")\n",
    "    number_of_duplicate_rows = df.duplicated().sum()\n",
    "    print(f\"Número total de filas duplicadas encontradas: {number_of_duplicate_rows}\")\n",
    "    \n",
    "    if number_of_duplicate_rows == 0:\n",
    "        print(\"No se han encontrado filas duplicadas en el dataset.\")\n",
    "    else:\n",
    "        # Si hay duplicados, podríamos querer verlos (si no son demasiados).\n",
    "        # display(df[df.duplicated(keep=False)].sort_values(by=list(df.columns))) # Muestra todas las ocurrencias de duplicados\n",
    "        print(\"Se han detectado filas duplicadas. Se revisará su manejo en la etapa de limpieza de datos.\")\n",
    "\n",
    "else:\n",
    "    print(\"El DataFrame `df` está vacío o no definido. Imposible realizar análisis de calidad de datos.\")\n",
    "    print(\"Por favor, verifique la ejecución de las celdas anteriores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7eac7-8154-4e01-accd-03db4cd6120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIMPIEZA DE DATOS\n",
    "# -------------------------\n",
    "# Basándonos en los hallazgos de la inspección inicial (Celdas 3 y 4),\n",
    "# procedemos con las tareas de limpieza necesarias. Esto puede incluir\n",
    "# corrección de nombres de columnas, manejo de duplicados, y ajuste de tipos de datos.\n",
    "\n",
    "if 'df' in locals() and not df.empty:\n",
    "    print(\"--- Iniciando Proceso de Limpieza de Datos ---\")\n",
    "\n",
    "    # 1. Corrección de Nombres de Columnas:\n",
    "    #    Aseguramos que los nombres sean consistentes y fáciles de usar (sin espacios extra, usando guiones bajos).\n",
    "    print(\"\\nNombres de columnas antes de la corrección:\", df.columns.tolist())\n",
    "    original_column_names = df.columns.tolist() # Guardamos por si hay cambios\n",
    "    \n",
    "    df.columns = df.columns.str.strip() # Elimina espacios en blanco al inicio y al final.\n",
    "    df.columns = df.columns.str.replace(' ', '_') # Reemplaza espacios intermedios por guiones bajos.\n",
    "                                                 # También convierte a minúsculas para consistencia (opcional pero común).\n",
    "    df.columns = df.columns.str.lower()\n",
    "    \n",
    "    if df.columns.tolist() != original_column_names:\n",
    "        print(\"Nombres de columnas después de la corrección:\", df.columns.tolist())\n",
    "    else:\n",
    "        print(\"No fue necesario modificar los nombres de las columnas (ya estaban en formato adecuado).\")\n",
    "    \n",
    "    # 2. Manejo de Filas Duplicadas:\n",
    "    #    Si se detectaron filas duplicadas en la celda anterior, aquí las eliminamos.\n",
    "    #    Usualmente, se conserva la primera aparición ('keep=first').\n",
    "    num_duplicates_before = df.duplicated().sum()\n",
    "    if num_duplicates_before > 0:\n",
    "        print(f\"\\nSe encontraron {num_duplicates_before} filas duplicadas. Procediendo a eliminarlas...\")\n",
    "        df.drop_duplicates(inplace=True, keep='first')\n",
    "        print(f\"Filas duplicadas eliminadas. Nuevas dimensiones del DataFrame: {df.shape}\")\n",
    "        # Es buena práctica resetear el índice después de eliminar filas.\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        print(\"Índice del DataFrame reseteado.\")\n",
    "    else:\n",
    "        print(\"\\nNo se encontraron filas duplicadas para eliminar.\")\n",
    "\n",
    "    # 3. Transformación de la Variable Objetivo (si es necesario y no se hizo antes):\n",
    "    #    En la Celda 2, mapeamos 'diagnosis' de 0/1 a 'malignant'/'benign'.\n",
    "    #    Para los modelos, necesitaremos que sea numérica (0/1). Esta transformación\n",
    "    #    se hará más adelante (Celda 11) de forma más específica para la preparación de X e y.\n",
    "    #    Este bloque es un recordatorio de que si tuviéramos otras columnas objetivo textuales,\n",
    "    #    aquí sería un buen lugar para mapearlas a números.\n",
    "    #    Por ejemplo, si 'diagnosis' aún no fuera 'category':\n",
    "    if 'diagnosis' in df.columns and df['diagnosis'].dtype == 'object':\n",
    "         print(\"\\nLa columna 'diagnosis' es de tipo 'object'. Convirtiendo a 'category' para optimización.\")\n",
    "         df['diagnosis'] = df['diagnosis'].astype('category')\n",
    "    elif 'diagnosis' in df.columns and pd.api.types.is_categorical_dtype(df['diagnosis']):\n",
    "         print(\"\\nLa columna 'diagnosis' ya es de tipo 'category'.\")\n",
    "    else:\n",
    "         print(\"\\nLa columna 'diagnosis' no se encontró o no es 'object' ni 'category'. Revisar.\")\n",
    "\n",
    "\n",
    "    # 4. Asegurar Tipos de Datos Categóricos para otras variables (si las hubiera):\n",
    "    #    Si alguna otra columna de texto debiera ser tratada como una categoría,\n",
    "    #    la convertimos explícitamente. Esto puede optimizar el uso de memoria y\n",
    "    #    es requerido por algunas funciones de pandas o scikit-learn.\n",
    "    print(\"\\nAsegurando que otras columnas textuales con baja cardinalidad sean de tipo 'category'...\")\n",
    "    changed_types_count = 0\n",
    "    for col_name in df.select_dtypes(include=['object']).columns:\n",
    "        # Excluimos la columna 'diagnosis' ya que la manejamos/manejaremos específicamente.\n",
    "        if col_name == 'diagnosis':\n",
    "            continue\n",
    "        \n",
    "        # Consideramos una columna como categórica si tiene un número de valores únicos\n",
    "        # relativamente bajo en comparación con el total de filas.\n",
    "        # Y más de 1 valor único (si solo tiene 1, no aporta mucha información como categoría).\n",
    "        if 1 < df[col_name].nunique() < len(df) * 0.1: # Umbral del 10% de valores únicos\n",
    "            print(f\"Convirtiendo la columna '{col_name}' (con {df[col_name].nunique()} valores únicos) a tipo 'category'.\")\n",
    "            df[col_name] = df[col_name].astype('category')\n",
    "            changed_types_count += 1\n",
    "    if changed_types_count == 0 and not any(col == 'diagnosis' for col in df.select_dtypes(include=['object']).columns):\n",
    "        print(\"No se identificaron otras columnas 'object' para convertir a 'category' (o ya lo son).\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Proceso de Limpieza de Datos Completado ---\")\n",
    "    print(\"\\nInformación actualizada del DataFrame (df.info()):\")\n",
    "    df.info()\n",
    "    \n",
    "else:\n",
    "    print(\"El DataFrame `df` está vacío o no definido. No se puede proceder con la limpieza.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677aa4f1-3e1a-46c5-983c-b772239b6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÁLISIS EXPLORATORIO DE DATOS (EDA) - VARIABLE OBJETIVO \n",
    "# ------------------------------------------------------------------------\n",
    "# Analizamos la distribución de la variable objetivo (diagnosis en nuestro dataset actual)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Primero verificamos qué columnas están disponibles en nuestro dataset\n",
    "print(\"Columnas disponibles en el dataset:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Identificar la variable objetivo (probablemente 'diagnosis' en vez de 'Status')\n",
    "target_column = None\n",
    "\n",
    "# Buscar la columna objetivo más probable\n",
    "if not df.empty:\n",
    "    potential_targets = ['diagnosis', 'target', 'label', 'class', 'Status']\n",
    "    for col in potential_targets:\n",
    "        if col in df.columns:\n",
    "            target_column = col\n",
    "            break\n",
    "    \n",
    "    # Si no encontramos ninguna de las columnas típicas, intentamos detectar automáticamente\n",
    "    if target_column is None:\n",
    "        # Buscar columnas con pocas categorías (típicamente 2-5)\n",
    "        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        for col in categorical_cols:\n",
    "            if df[col].nunique() <= 5:  # Asumimos que una columna categórica con pocas categorías podría ser el objetivo\n",
    "                target_column = col\n",
    "                print(f\"Se detectó automáticamente '{col}' como posible variable objetivo.\")\n",
    "                break\n",
    "\n",
    "# Si aún no tenemos variable objetivo y tenemos pocas columnas, mostramos los valores únicos de cada una\n",
    "if target_column is None and df.shape[1] < 15:\n",
    "    print(\"\\nNo se identificó automáticamente una variable objetivo. Mostrando valores únicos de cada columna:\")\n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].nunique()\n",
    "        if unique_values < 10:  # Solo mostramos columnas con pocos valores únicos\n",
    "            print(f\"Columna '{col}': {unique_values} valores únicos - {df[col].unique()}\")\n",
    "\n",
    "# Proceder con el análisis si encontramos una variable objetivo\n",
    "if target_column is not None:\n",
    "    print(f\"\\n--- Análisis de la Variable Objetivo ('{target_column}') ---\")\n",
    "    \n",
    "    target_counts = df[target_column].value_counts()\n",
    "    target_percentage = df[target_column].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(\"\\nConteo por categoría:\")\n",
    "    print(target_counts)\n",
    "    print(\"\\nPorcentaje por categoría:\")\n",
    "    print(target_percentage)\n",
    "    \n",
    "    # Crear un mapa de colores para las categorías\n",
    "    if len(target_counts) == 2:\n",
    "        color_palette = ['#3498db', '#e74c3c']  # Azul y rojo para caso binario\n",
    "    else:\n",
    "        color_palette = sns.color_palette(\"viridis\", len(target_counts))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.countplot(x=target_column, data=df, palette=color_palette)\n",
    "    plt.title(f'Distribución de la Variable Objetivo ({target_column})', fontsize=16)\n",
    "    plt.xlabel(target_column, fontsize=14)\n",
    "    plt.ylabel('Número de Muestras', fontsize=14)\n",
    "    \n",
    "    # Generar etiquetas descriptivas para el eje x si son valores numéricos\n",
    "    if df[target_column].dtype in [np.int64, np.int32, np.float64]:\n",
    "        category_labels = [f\"{val}\" for val in sorted(df[target_column].unique())]\n",
    "        plt.xticks(ticks=range(len(category_labels)), labels=category_labels)\n",
    "    \n",
    "    # Añadir anotaciones de porcentaje\n",
    "    for i, count_val in enumerate(target_counts):\n",
    "        percentage_val = target_percentage[target_counts.index[i]]\n",
    "        plt.text(i, count_val + (max(target_counts) * 0.05), \n",
    "                 f'{percentage_val:.1f}% ({count_val})', \n",
    "                 ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Comprobar si hay desequilibrio de clases\n",
    "    if len(target_percentage) == 2:  # Solo verificamos desequilibrio para problemas binarios\n",
    "        imbalance_ratio = max(target_percentage) / min(target_percentage)\n",
    "        if imbalance_ratio > 1.5:  # Umbral arbitrario para desequilibrio\n",
    "            print(f\"\\nObservación: El dataset presenta un desequilibrio de clases (ratio {imbalance_ratio:.2f}:1).\")\n",
    "            print(\"Esto deberá tenerse en cuenta durante el modelado (e.g., usando métricas apropiadas, stratify en train_test_split, o técnicas de re-muestreo).\")\n",
    "    \n",
    "    # Mostrar distribución en formato pie chart para mejor visualización\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    explode = [0.05] * len(target_counts)  # Explotar ligeramente todas las porciones\n",
    "    plt.pie(target_counts, labels=[f\"{idx} ({val})\" for idx, val in target_counts.items()], \n",
    "            autopct='%1.1f%%', startangle=90, explode=explode, \n",
    "            colors=color_palette, shadow=True)\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "    plt.title(f'Distribución de {target_column} (Gráfico de Torta)', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"\\nNo se pudo identificar una columna adecuada como variable objetivo.\")\n",
    "    print(\"Por favor, especifica manualmente la columna objetivo a analizar.\")\n",
    "    \n",
    "    # Mostrar un resumen de todas las columnas para ayudar al usuario a identificar la variable objetivo\n",
    "    print(\"\\nResumen de todas las columnas disponibles:\")\n",
    "    for col in df.columns:\n",
    "        dtype = df[col].dtype\n",
    "        n_unique = df[col].nunique()\n",
    "        if n_unique < 20:  # Solo mostrar valores únicos si son pocos\n",
    "            print(f\"- {col}: {dtype}, {n_unique} valores únicos: {df[col].unique()}\")\n",
    "        else:\n",
    "            print(f\"- {col}: {dtype}, {n_unique} valores únicos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3179084-bb77-45eb-9778-98f5463a6c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA - ANÁLISIS UNIVARIADO DE CARACTERÍSTICAS NUMÉRICAS\n",
    "# ---------------------------------------------------------------\n",
    "# Después de analizar la variable objetivo, exploramos cada característica numérica de forma individual.\n",
    "# El objetivo es entender la distribución de cada una: su forma, tendencia central, dispersión,\n",
    "# y la presencia de posibles valores atípicos (outliers).\n",
    "# Usaremos histogramas y diagramas de caja (boxplots) para esta tarea.\n",
    "\n",
    "# matplotlib.pyplot y seaborn ya deberían estar importados.\n",
    "# numpy también.\n",
    "\n",
    "if 'df' in locals() and not df.empty:\n",
    "    print(\"--- EDA: Análisis Univariado de Características Numéricas ---\")\n",
    "    \n",
    "    # Seleccionamos las columnas que son de tipo numérico.\n",
    "    # Excluimos cualquier columna que sea la variable objetivo si esta fuera numérica (aunque 'diagnosis' es categórica).\n",
    "    # También es buena práctica excluir columnas que parezcan IDs si son numéricas.\n",
    "    \n",
    "    numeric_cols_for_eda = df.select_dtypes(include=np.number).columns.tolist()\n",
    "    \n",
    "    # Si 'target_col_eda' (definida en Celda 6) es una columna numérica, la removemos de esta lista.\n",
    "    # Esto es poco probable en nuestro caso ya que 'diagnosis' es el objetivo y es categórico.\n",
    "    if 'target_col_eda' in locals() and target_col_eda in numeric_cols_for_eda:\n",
    "        print(f\"Excluyendo la columna objetivo '{target_col_eda}' del análisis de características numéricas.\")\n",
    "        numeric_cols_for_eda.remove(target_col_eda)\n",
    "        \n",
    "    # Identificar y excluir posibles columnas de ID que puedan ser numéricas.\n",
    "    # Un ID suele tener tantos valores únicos como filas, o contener 'id' en su nombre.\n",
    "    potential_id_cols = [\n",
    "        col for col in numeric_cols_for_eda \n",
    "        if 'id' in col.lower() or df[col].nunique() >= len(df) * 0.95 # Si casi todos los valores son únicos\n",
    "    ]\n",
    "    if potential_id_cols:\n",
    "        print(f\"Excluyendo posibles columnas ID del análisis numérico: {potential_id_cols}\")\n",
    "        for id_col in potential_id_cols:\n",
    "            if id_col in numeric_cols_for_eda: # Comprobar si aún está en la lista\n",
    "                numeric_cols_for_eda.remove(id_col)\n",
    "\n",
    "    if numeric_cols_for_eda:\n",
    "        print(f\"Se analizarán {len(numeric_cols_for_eda)} características numéricas.\")\n",
    "        \n",
    "        # Definimos cómo organizar los múltiples gráficos.\n",
    "        num_plots_per_row = 3\n",
    "        num_rows_for_plots = int(np.ceil(len(numeric_cols_for_eda) / num_plots_per_row))\n",
    "\n",
    "        # 1. Histogramas para visualizar la distribución (forma, sesgo, multimodalidad).\n",
    "        #    KDE (Kernel Density Estimate) superpuesto ayuda a ver la forma de la distribución.\n",
    "        plt.figure(figsize=(num_plots_per_row * 5, num_rows_for_plots * 4)) # Ajustar tamaño dinámicamente\n",
    "        plt.suptitle(\"Distribución de Características Numéricas (Histogramas + KDE)\", fontsize=18, weight='bold', y=1.03)\n",
    "        for i, col_name in enumerate(numeric_cols_for_eda):\n",
    "            plt.subplot(num_rows_for_plots, num_plots_per_row, i + 1)\n",
    "            sns.histplot(df[col_name], kde=True, bins=30, color='skyblue', edgecolor='black', line_kws={'linewidth': 2})\n",
    "            plt.title(f'{col_name.replace(\"_\", \" \").capitalize()}', fontsize=14)\n",
    "            plt.xlabel(col_name.replace(\"_\", \" \").capitalize(), fontsize=12)\n",
    "            plt.ylabel('Frecuencia', fontsize=12)\n",
    "            plt.xticks(fontsize=10)\n",
    "            plt.yticks(fontsize=10)\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.98]) # Ajuste para el supertítulo\n",
    "        plt.show()\n",
    "\n",
    "        # 2. Diagramas de Caja (Boxplots) para identificar la mediana, cuartiles y valores atípicos.\n",
    "        plt.figure(figsize=(num_plots_per_row * 5, num_rows_for_plots * 4))\n",
    "        plt.suptitle(\"Dispersión de Características Numéricas (Diagramas de Caja)\", fontsize=18, weight='bold', y=1.03)\n",
    "        for i, col_name in enumerate(numeric_cols_for_eda):\n",
    "            plt.subplot(num_rows_for_plots, num_plots_per_row, i + 1)\n",
    "            sns.boxplot(y=df[col_name], color='lightcoral', width=0.5)\n",
    "            plt.title(f'{col_name.replace(\"_\", \" \").capitalize()}', fontsize=14)\n",
    "            plt.ylabel(col_name.replace(\"_\", \" \").capitalize(), fontsize=12)\n",
    "            plt.xticks(fontsize=10) # Aunque no hay etiquetas X, para consistencia del tamaño de fuente\n",
    "            plt.yticks(fontsize=10)\n",
    "            plt.grid(True, linestyle='--', alpha=0.7, axis='y') # Rejilla solo en el eje Y\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No se encontraron características numéricas (distintas de la objetivo o IDs) para analizar.\")\n",
    "else:\n",
    "    print(\"El DataFrame `df` está vacío o no definido. No se puede realizar el análisis univariado numérico.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02652b2c-941d-486b-bba1-152961880d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÁLISIS UNIVARIADO DE CARACTERÍSTICAS CATEGÓRICAS\n",
    "# -----------------------------------------------------------------\n",
    "# Después de las numéricas, analizamos las características categóricas.\n",
    "# Estas son variables que representan grupos o categorías, como 'tipo A', 'tipo B', etc.\n",
    "# En nuestro dataset de cáncer de mama, la principal variable categórica es 'diagnosis'.\n",
    "# Si tuviéramos otras (por ejemplo, 'estadio del tumor' si fuera textual), las analizaríamos aquí.\n",
    "# El objetivo es ver la frecuencia de cada categoría.\n",
    "\n",
    "# matplotlib.pyplot y seaborn ya deberían estar importados.\n",
    "\n",
    "if 'df' in locals() and not df.empty:\n",
    "    print(\"--- EDA: Análisis Univariado de Características Categóricas ---\")\n",
    "    \n",
    "    # Seleccionamos columnas de tipo 'category' u 'object' (texto).\n",
    "    # La variable 'target_col_eda' fue identificada en la Celda 6 (debería ser 'diagnosis').\n",
    "    # Aquí, estamos interesados en la distribución de 'diagnosis' misma como categórica,\n",
    "    # y cualquier OTRA característica predictora que sea categórica.\n",
    "    \n",
    "    categorical_cols_for_eda = df.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "    \n",
    "    # Si no hay características categóricas, lo indicamos.\n",
    "    if not categorical_cols_for_eda:\n",
    "        print(\"No se encontraron características categóricas para analizar en este paso.\")\n",
    "    else:\n",
    "        print(f\"Se analizarán {len(categorical_cols_for_eda)} características categóricas: {categorical_cols_for_eda}\")\n",
    "        \n",
    "        # Definimos cómo organizar los gráficos.\n",
    "        num_plots_per_row_cat = 2  # Ajustar si hay muchas o pocas\n",
    "        if len(categorical_cols_for_eda) == 1:\n",
    "            num_plots_per_row_cat = 1 # Si solo hay una, que ocupe más espacio\n",
    "            \n",
    "        num_rows_for_plots_cat = int(np.ceil(len(categorical_cols_for_eda) / num_plots_per_row_cat))\n",
    "\n",
    "        if num_rows_for_plots_cat > 0: # Solo crear figura si hay algo que plotear\n",
    "            plt.figure(figsize=(num_plots_per_row_cat * 7, num_rows_for_plots_cat * 5)) # Tamaño dinámico\n",
    "            plt.suptitle(\"Distribución de Características Categóricas\", fontsize=18, weight='bold', y=1.03 if len(categorical_cols_for_eda) > 1 else 1.05)\n",
    "\n",
    "            for i, col_name in enumerate(categorical_cols_for_eda):\n",
    "                plt.subplot(num_rows_for_plots_cat, num_plots_per_row_cat, i + 1)\n",
    "                \n",
    "                # Ordenamos las barras por frecuencia para una mejor visualización.\n",
    "                value_order = df[col_name].value_counts().index\n",
    "                \n",
    "                # Usamos countplot. Si las etiquetas de categoría son largas, 'orient=\"h\"' (o y=col_name) es mejor.\n",
    "                ax_cat_countplot = sns.countplot(\n",
    "                    data=df, \n",
    "                    y=col_name, # Barras horizontales, bueno para etiquetas de categoría\n",
    "                    order=value_order, \n",
    "                    palette='viridis_r' # Paleta de colores\n",
    "                )\n",
    "                \n",
    "                plt.title(f'{col_name.replace(\"_\", \" \").capitalize()}', fontsize=14)\n",
    "                plt.xlabel('Conteo de Observaciones', fontsize=12)\n",
    "                plt.ylabel(col_name.replace(\"_\", \" \").capitalize(), fontsize=12)\n",
    "                plt.xticks(fontsize=10)\n",
    "                plt.yticks(fontsize=10)\n",
    "                plt.grid(True, linestyle='--', alpha=0.7, axis='x') # Rejilla en el eje X para barras horizontales\n",
    "\n",
    "                # Añadir conteos al final de cada barra.\n",
    "                for p_patch in ax_cat_countplot.patches:\n",
    "                    width = p_patch.get_width()\n",
    "                    ax_cat_countplot.text(\n",
    "                        width + (ax_cat_countplot.get_xlim()[1] * 0.01), # Pequeño offset del final de la barra\n",
    "                        p_patch.get_y() + p_patch.get_height() / 2.,\n",
    "                        f'{int(width)}', # El conteo\n",
    "                        va='center', \n",
    "                        ha='left', # Alineado a la izquierda del texto\n",
    "                        fontsize=10, \n",
    "                        color='black'\n",
    "                    )\n",
    "            \n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.97]) # Ajuste para el supertítulo\n",
    "            plt.show()\n",
    "        elif categorical_cols_for_eda: # Hay columnas pero no se generaron filas para plots (raro)\n",
    "             print(f\"Se identificaron columnas categóricas {categorical_cols_for_eda} pero no se generaron gráficos. Revisar lógica.\")\n",
    "\n",
    "else:\n",
    "    print(\"El DataFrame `df` está vacío o no definido. No se puede realizar el análisis univariado categórico.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e3ec90-34f8-4760-96e4-01aee0af1a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÁLISIS BIVARIADO (CARACTERÍSTICAS VS. VARIABLE OBJETIVO)\n",
    "# ------------------------------------------------------------------------\n",
    "# Esta es una etapa crucial del EDA. Aquí exploramos cómo cada característica predictora\n",
    "# se relaciona con nuestra variable objetivo ('diagnosis').\n",
    "# Buscamos identificar qué características parecen tener una influencia o una\n",
    "# distribución diferente para los casos benignos versus los malignos.\n",
    "# Esto nos da pistas tempranas sobre qué variables podrían ser más importantes para nuestros modelos.\n",
    "\n",
    "# matplotlib.pyplot, seaborn, pandas, numpy ya deberían estar disponibles.\n",
    "# from sklearn.preprocessing import LabelEncoder # Para codificar la objetivo para correlaciones.\n",
    "\n",
    "if 'df' in locals() and not df.empty and 'target_col_eda' in locals() and target_col_eda:\n",
    "    # 'target_col_eda' fue definida en la Celda 6 (debería ser 'diagnosis').\n",
    "    # 'numeric_cols_for_eda' fue definida en la Celda 7.\n",
    "    # 'categorical_cols_for_eda' fue definida en la Celda 8.\n",
    "\n",
    "    print(f\"--- EDA: Análisis Bivariado (Características Predictoras vs. '{target_col_eda}') ---\")\n",
    "    \n",
    "    # Usaremos una copia para cualquier transformación temporal (como codificar 'diagnosis' para correlaciones).\n",
    "    df_bivariate_analysis = df.copy()\n",
    "\n",
    "    # Colores consistentes para las clases de la variable objetivo.\n",
    "    palette_for_target = {'benign': '#3498db', 'malignant': '#e74c3c'} if target_col_eda == 'diagnosis' and set(df[target_col_eda].unique()) == {'benign', 'malignant'} else sns.color_palette(\"husl\", df[target_col_eda].nunique())\n",
    "\n",
    "\n",
    "    # 1. Características Numéricas Predictoras vs. Variable Objetivo.\n",
    "    #    Visualizamos con boxplots y violinplots para comparar distribuciones.\n",
    "    if 'numeric_cols_for_eda' in locals() and numeric_cols_for_eda:\n",
    "        print(f\"\\n--- Relación: Características Numéricas vs. '{target_col_eda}' ---\")\n",
    "        \n",
    "        # Limitamos el número de gráficos para no saturar; podríamos seleccionar las más prometedoras\n",
    "        # o las primeras N. Aquí tomamos las primeras 9-12 para el ejemplo.\n",
    "        features_to_plot_num_vs_target = numeric_cols_for_eda[:min(12, len(numeric_cols_for_eda))]\n",
    "        \n",
    "        num_plot_cols_biv = 3\n",
    "        num_plot_rows_biv = int(np.ceil(len(features_to_plot_num_vs_target) / num_plot_cols_biv))\n",
    "\n",
    "        if num_plot_rows_biv > 0:\n",
    "            # Boxplots: Comparan la distribución (mediana, cuartiles, outliers) de cada numérica para cada clase del target.\n",
    "            plt.figure(figsize=(num_plot_cols_biv * 6, num_plot_rows_biv * 5))\n",
    "            plt.suptitle(f\"Características Numéricas vs. {target_col_eda.replace('_',' ').capitalize()} (Diagramas de Caja)\", fontsize=18, weight='bold', y=1.03)\n",
    "            for i, col in enumerate(features_to_plot_num_vs_target):\n",
    "                plt.subplot(num_plot_rows_biv, num_plot_cols_biv, i + 1)\n",
    "                sns.boxplot(x=target_col_eda, y=col, data=df_bivariate_analysis, palette=palette_for_target, width=0.6)\n",
    "                plt.title(f'{col.replace(\"_\",\" \").capitalize()}', fontsize=14)\n",
    "                plt.xlabel(target_col_eda.replace(\"_\",\" \").capitalize(), fontsize=12)\n",
    "                plt.ylabel(col.replace(\"_\",\" \").capitalize(), fontsize=12)\n",
    "                plt.xticks(fontsize=11); plt.yticks(fontsize=11)\n",
    "                plt.grid(True, linestyle='--', alpha=0.6, axis='y')\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "            plt.show()\n",
    "\n",
    "            # Violinplots: Similar a boxplots pero también muestran la forma de la distribución (como un KDE).\n",
    "            plt.figure(figsize=(num_plot_cols_biv * 6, num_plot_rows_biv * 5))\n",
    "            plt.suptitle(f\"Características Numéricas vs. {target_col_eda.replace('_',' ').capitalize()} (Diagramas de Violín)\", fontsize=18, weight='bold', y=1.03)\n",
    "            for i, col in enumerate(features_to_plot_num_vs_target):\n",
    "                plt.subplot(num_plot_rows_biv, num_plot_cols_biv, i + 1)\n",
    "                sns.violinplot(x=target_col_eda, y=col, data=df_bivariate_analysis, palette=palette_for_target, inner='quartile', cut=0)\n",
    "                plt.title(f'{col.replace(\"_\",\" \").capitalize()}', fontsize=14)\n",
    "                plt.xlabel(target_col_eda.replace(\"_\",\" \").capitalize(), fontsize=12)\n",
    "                plt.ylabel(col.replace(\"_\",\" \").capitalize(), fontsize=12)\n",
    "                plt.xticks(fontsize=11); plt.yticks(fontsize=11)\n",
    "                plt.grid(True, linestyle='--', alpha=0.6, axis='y')\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"No hay suficientes características numéricas seleccionadas para graficar contra el objetivo.\")\n",
    "    else:\n",
    "        print(\"No se encontraron características numéricas predictoras para el análisis bivariado.\")\n",
    "\n",
    "    # 2. Características Categóricas Predictoras (si las hay) vs. Variable Objetivo.\n",
    "    #    Usamos tablas de contingencia y gráficos de barras apiladas.\n",
    "    #    En nuestro caso, 'categorical_cols_for_eda' de la Celda 8 probablemente solo contenía 'diagnosis'.\n",
    "    #    Aquí buscamos OTRAS predictoras categóricas.\n",
    "    other_cat_predictors = [col for col in df_bivariate_analysis.select_dtypes(include=['category', 'object']).columns if col != target_col_eda]\n",
    "    \n",
    "    if other_cat_predictors:\n",
    "        print(f\"\\n--- Relación: Características Categóricas Predictoras vs. '{target_col_eda}' ---\")\n",
    "        num_plot_cols_cat_biv = 2\n",
    "        num_plot_rows_cat_biv = int(np.ceil(len(other_cat_predictors) / num_plot_cols_cat_biv))\n",
    "\n",
    "        if num_plot_rows_cat_biv > 0:\n",
    "            plt.figure(figsize=(num_plot_cols_cat_biv * 8, num_plot_rows_cat_biv * 6))\n",
    "            plt.suptitle(f\"Predictoras Categóricas vs. {target_col_eda.replace('_',' ').capitalize()} (Barras Apiladas %)\", fontsize=18, weight='bold', y=1.03)\n",
    "            for i, col in enumerate(other_cat_predictors):\n",
    "                ax_sub = plt.subplot(num_plot_rows_cat_biv, num_plot_cols_cat_biv, i + 1)\n",
    "                # Creamos una tabla de contingencia normalizada por índice (porcentaje por cada categoría de 'col')\n",
    "                contingency_table_norm = pd.crosstab(df_bivariate_analysis[col], df_bivariate_analysis[target_col_eda], normalize='index') * 100\n",
    "                contingency_table_norm.plot(kind='barh', stacked=True, ax=ax_sub, colormap='coolwarm_r', width=0.8)\n",
    "                plt.title(f'{col.replace(\"_\",\" \").capitalize()}', fontsize=14)\n",
    "                plt.xlabel(f'Porcentaje de {target_col_eda.replace(\"_\",\" \").capitalize()}', fontsize=12)\n",
    "                plt.ylabel(col.replace(\"_\",\" \").capitalize(), fontsize=12)\n",
    "                plt.xticks(fontsize=11); plt.yticks(fontsize=11)\n",
    "                plt.legend(title=target_col_eda.replace(\"_\",\" \").capitalize(), bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "                # Añadir etiquetas de porcentaje dentro de las barras\n",
    "                for n, (idx, row) in enumerate(contingency_table_norm.iterrows()):\n",
    "                    cumulative_width = 0\n",
    "                    for m, val in enumerate(row):\n",
    "                        width = val\n",
    "                        if width > 5: # Solo mostrar si el segmento es suficientemente grande\n",
    "                            plt.text(cumulative_width + width/2, n, f\"{width:.1f}%\", \n",
    "                                     va='center', ha='center', fontsize=9, color='white' if width > 40 else 'black')\n",
    "                        cumulative_width += width\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(f\"\\nNo se encontraron OTRAS características categóricas predictoras para comparar con '{target_col_eda}'.\")\n",
    "\n",
    "    # 3. Matriz de Correlación (entre numéricas y la objetivo codificada).\n",
    "    #    Reutilizamos 'numeric_cols_for_eda'.\n",
    "    if 'numeric_cols_for_eda' in locals() and numeric_cols_for_eda:\n",
    "        print(\"\\n--- Correlación entre Características Numéricas y la Variable Objetivo (Codificada) ---\")\n",
    "        df_for_correlation = df_bivariate_analysis[numeric_cols_for_eda].copy()\n",
    "        \n",
    "        # Necesitamos la variable objetivo en formato numérico para la correlación.\n",
    "        # Usamos LabelEncoder: asignará 0 a una clase y 1 a la otra (alfabéticamente si no se especifica).\n",
    "        # Si 'benign' es 0 y 'malignant' es 1, una correlación positiva con 'diagnosis_encoded'\n",
    "        # significa que al aumentar la característica, aumenta la probabilidad de ser 'malignant'.\n",
    "        le = LabelEncoder()\n",
    "        df_for_correlation[target_col_eda + \"_encoded\"] = le.fit_transform(df_bivariate_analysis[target_col_eda])\n",
    "        \n",
    "        print(f\"Clases codificadas para '{target_col_eda}': {list(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "\n",
    "        correlation_matrix_with_target = df_for_correlation.corr()\n",
    "        \n",
    "        # Extraemos solo la columna de correlaciones con la variable objetivo.\n",
    "        target_correlations = correlation_matrix_with_target[target_col_eda + \"_encoded\"].drop(target_col_eda + \"_encoded\")\n",
    "        target_correlations_sorted = target_correlations.sort_values(ascending=False)\n",
    "        \n",
    "        print(\"\\nCorrelaciones de Pearson más significativas con la variable objetivo codificada:\")\n",
    "        print(\"Top 10 Positivas (más asociadas con la clase '1' - e.g., 'malignant'):\")\n",
    "        print(target_correlations_sorted.head(10))\n",
    "        print(\"\\nTop 10 Negativas (más asociadas con la clase '0' - e.g., 'benign'):\")\n",
    "        print(target_correlations_sorted.abs().sort_values(ascending=False).tail(10) if target_correlations_sorted.min() < 0 else \"No hay correlaciones negativas significativas.\")\n",
    "\n",
    "\n",
    "        # Visualización de estas correlaciones.\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        # Colores diferentes para correlaciones positivas y negativas.\n",
    "        colors = ['crimson' if c < 0 else 'royalblue' for c in target_correlations_sorted.values]\n",
    "        target_correlations_sorted.plot(kind='bar', color=colors)\n",
    "        plt.title(f'Correlación de Características con {target_col_eda.replace(\"_\",\" \").capitalize()} (Codificada)', fontsize=16, weight='bold')\n",
    "        plt.ylabel('Coeficiente de Correlación de Pearson', fontsize=12)\n",
    "        plt.xlabel('Características', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.axhline(0, color='black', linewidth=0.8) # Línea en cero\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No se pudieron calcular correlaciones con el objetivo (faltan características numéricas o el objetivo).\")\n",
    "\n",
    "else:\n",
    "    print(\"El DataFrame `df` está vacío o la variable objetivo `target_col_eda` no fue definida. No se puede realizar análisis bivariado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75d910-9639-48df-8b3a-e181e4759fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA - MATRIZ DE CORRELACIÓN (ENTRE CARACTERÍSTICAS NUMÉRICAS PREDICTORAS)\n",
    "# ---------------------------------------------------------------------------------\n",
    "# En la celda anterior, vimos la correlación de cada característica numérica con la variable objetivo.\n",
    "# Ahora, vamos a analizar la correlación ENTRE las propias características predictoras numéricas.\n",
    "# El objetivo es identificar si existen pares o grupos de características que estén fuertemente\n",
    "# correlacionadas entre sí (lo que se conoce como multicolinealidad).\n",
    "# Esto es importante porque algunos modelos pueden ser sensibles a la multicolinealidad,\n",
    "# y también nos indica si algunas variables podrían estar proporcionando información redundante.\n",
    "\n",
    "# matplotlib.pyplot, seaborn, pandas, numpy ya deberían estar disponibles.\n",
    "\n",
    "if 'df' in locals() and not df.empty:\n",
    "    # 'numeric_cols_for_eda' fue definida en la Celda 7 y ya excluye IDs y la objetivo si fuera numérica.\n",
    "    if 'numeric_cols_for_eda' in locals() and numeric_cols_for_eda:\n",
    "        \n",
    "        if len(numeric_cols_for_eda) > 1:\n",
    "            print(\"--- EDA: Matriz de Correlación entre Características Numéricas Predictoras ---\")\n",
    "\n",
    "            # Calculamos la matriz de correlación de Pearson para las características seleccionadas.\n",
    "            correlation_matrix_predictors_only = df[numeric_cols_for_eda].corr()\n",
    "            \n",
    "            # Visualizamos esta matriz usando un mapa de calor (heatmap).\n",
    "            # Un heatmap es ideal para representar matrices de correlación,\n",
    "            # usando colores para indicar la fuerza y dirección de la correlación.\n",
    "            plt.figure(figsize=(20, 18)) # Hacemos esta figura bastante grande para que se lean las etiquetas\n",
    "            sns.heatmap(\n",
    "                correlation_matrix_predictors_only,\n",
    "                annot=True,        # Muestra los valores numéricos de correlación en cada celda.\n",
    "                cmap='coolwarm',   # Paleta de colores: 'coolwarm' va de azul (negativo) a rojo (positivo), pasando por blanco (cero).\n",
    "                fmt=\".2f\",         # Formato de los números (2 decimales).\n",
    "                linewidths=.5,     # Líneas delgadas para separar las celdas.\n",
    "                cbar_kws={\"shrink\": .8} # Ajustar el tamaño de la barra de color.\n",
    "            )\n",
    "            plt.title('Matriz de Correlación entre Características Numéricas Predictoras', fontsize=20, weight='bold', pad=20)\n",
    "            plt.xticks(rotation=45, ha='right', fontsize=10) # Rotar etiquetas del eje X para mejor lectura\n",
    "            plt.yticks(fontsize=10)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"\\nInterpretación de la Matriz de Correlación entre Predictoras:\")\n",
    "            print(\" - Valores cercanos a +1 indican una fuerte correlación positiva (si una sube, la otra tiende a subir).\")\n",
    "            print(\" - Valores cercanos a -1 indican una fuerte correlación negativa (si una sube, la otra tiende a bajar).\")\n",
    "            print(\" - Valores cercanos a 0 indican una correlación lineal débil o nula.\")\n",
    "            print(\" - Una alta correlación entre dos (o más) variables predictoras (multicolinealidad) puede ser problemática:\")\n",
    "            print(\"   * Para la interpretabilidad de los coeficientes en modelos lineales.\")\n",
    "            print(\"   * Algunos algoritmos pueden volverse inestables o menos eficientes.\")\n",
    "            print(\"   * Podría indicar que algunas características son redundantes.\")\n",
    "            print(\" - No siempre es necesario eliminar características altamente correlacionadas, pero es fundamental ser consciente de ello.\")\n",
    "\n",
    "        else:\n",
    "            print(\"No hay suficientes características numéricas predictoras (se necesita más de una) para generar una matriz de correlación.\")\n",
    "    else:\n",
    "        print(\"La lista de características numéricas predictoras ('numeric_cols_for_eda') no está definida. Verifique la Celda 7.\")\n",
    "else:\n",
    "    print(\"El DataFrame `df` está vacío o no definido. No se puede generar la matriz de correlación.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0121481-e439-4496-ab50-98252be48b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESAMIENTO - CODIFICACIÓN DE LA VARIABLE OBJETIVO\n",
    "# -----------------------------------------------------------------\n",
    "# Los algoritmos de Machine Learning de scikit-learn requieren que tanto las características\n",
    "# predictoras (X) como la variable objetivo (y) sean numéricas.\n",
    "# Nuestra variable objetivo 'diagnosis' actualmente contiene etiquetas textuales ('malignant', 'benign').\n",
    "# En este paso, la convertiremos a un formato numérico (generalmente 0 y 1).\n",
    "\n",
    "# pandas ya debería estar importado.\n",
    "\n",
    "if 'df' in locals() and not df.empty:\n",
    "    print(\"--- Preprocesamiento: Codificación de la Variable Objetivo 'diagnosis' ---\")\n",
    "\n",
    "    # Hacemos una copia del DataFrame para este paso específico de preprocesamiento.\n",
    "    # Si bien podríamos modificar `df` directamente, crear `df_for_modeling`\n",
    "    # nos permite mantener `df` con 'diagnosis' textual por si lo necesitamos para EDA posterior.\n",
    "    # Sin embargo, para simplificar el flujo y dado que las celdas siguientes usarán `df`,\n",
    "    # actualizaremos `df` directamente después de la codificación.\n",
    "    \n",
    "    # df_for_modeling = df.copy() # Opción si quisiéramos mantener df intacto.\n",
    "\n",
    "    if 'diagnosis' in df.columns and (df['diagnosis'].dtype == 'object' or pd.api.types.is_categorical_dtype(df['diagnosis'])):\n",
    "        \n",
    "        print(f\"\\nValores únicos en 'diagnosis' antes de la codificación: {df['diagnosis'].unique().tolist()}\")\n",
    "        print(f\"Tipo de dato de 'diagnosis' antes: {df['diagnosis'].dtype}\")\n",
    "\n",
    "        # Usaremos pd.get_dummies con drop_first=True para una codificación binaria eficiente.\n",
    "        # Esto crea una nueva columna para una de las categorías (e.g., 'diagnosis_malignant')\n",
    "        # y le asigna 1 si la observación pertenece a esa categoría, y 0 en caso contrario.\n",
    "        # 'drop_first=True' elimina la redundancia: si no es 1 en 'diagnosis_malignant', entonces es 0 (benign).\n",
    "        # 'dtype=int' asegura que la nueva columna sea de tipo entero (0 o 1).\n",
    "\n",
    "        # Es importante saber qué categoría se \"dropea\" para interpretar el 0 y 1.\n",
    "        # pd.get_dummies ordena las categorías alfabéticamente y dropea la primera.\n",
    "        # Si nuestras categorías son 'benign' y 'malignant':\n",
    "        # 'benign' es la primera alfabéticamente, así que se crea 'diagnosis_malignant'.\n",
    "        # 'diagnosis_malignant' = 1 si la etiqueta original era 'malignant'.\n",
    "        # 'diagnosis_malignant' = 0 si la etiqueta original era 'benign'.\n",
    "        \n",
    "        print(\"\\nCodificando 'diagnosis' a formato numérico (0/1)...\")\n",
    "        df = pd.get_dummies(df, columns=['diagnosis'], drop_first=True, dtype=int)\n",
    "        \n",
    "        # Identificamos el nuevo nombre de la columna objetivo codificada.\n",
    "        # Debería ser 'diagnosis_malignant' si 'benign' fue la primera categoría alfabética.\n",
    "        new_encoded_target_column = [col for col in df.columns if col.startswith('diagnosis_')]\n",
    "        \n",
    "        if new_encoded_target_column:\n",
    "            new_encoded_target_column_name = new_encoded_target_column[0]\n",
    "            print(f\"La columna 'diagnosis' ha sido reemplazada por '{new_encoded_target_column_name}'.\")\n",
    "            print(f\"En '{new_encoded_target_column_name}': 1 representa la clase que NO fue eliminada (ej. 'malignant'), 0 representa la clase eliminada (ej. 'benign').\")\n",
    "            print(f\"Valores únicos en '{new_encoded_target_column_name}': {df[new_encoded_target_column_name].unique().tolist()}\")\n",
    "        else:\n",
    "            print(\"Advertencia: No se encontró la nueva columna objetivo después de get_dummies. Revisar nombres.\")\n",
    "\n",
    "        print(\"\\nVisualización de las primeras filas del DataFrame con 'diagnosis' codificada:\")\n",
    "        display(df.head())\n",
    "        print(f\"\\nDimensiones del DataFrame actualizadas: {df.shape}\")\n",
    "        print(\"\\nInformación de las columnas actualizada:\")\n",
    "        df.info()\n",
    "        \n",
    "    elif 'diagnosis' in df.columns and np.issubdtype(df['diagnosis'].dtype, np.number):\n",
    "        print(\"\\nLa columna 'diagnosis' ya parece ser numérica. No se requiere codificación adicional en este paso.\")\n",
    "        if df['diagnosis'].nunique() == 2:\n",
    "            print(f\"Valores únicos en 'diagnosis' numérica: {df['diagnosis'].unique().tolist()}\")\n",
    "        else:\n",
    "            print(f\"Advertencia: 'diagnosis' es numérica pero tiene {df['diagnosis'].nunique()} valores únicos. Se esperaba una variable binaria.\")\n",
    "    else:\n",
    "        print(\"\\nLa columna 'diagnosis' no se encontró o no es de un tipo adecuado para codificar con get_dummies en este flujo.\")\n",
    "        print(f\"Columnas actuales: {df.columns.tolist()}\")\n",
    "\n",
    "else:\n",
    "    print(\"El DataFrame `df` está vacío o no definido. No se puede proceder con la codificación.\")\n",
    "\n",
    "# Nota: A partir de esta celda, la variable `df` contendrá la columna objetivo ya codificada numéricamente\n",
    "# (por ejemplo, como 'diagnosis_malignant' con valores 0 y 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38198400-128c-48d7-98f6-a8e63b6f7ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESAMIENTO - DIVISIÓN EN CONJUNTOS DE ENTRENAMIENTO Y PRUEBA\n",
    "# ---------------------------------------------------------------------------\n",
    "# Este es un paso fundamental en cualquier proyecto de Machine Learning.\n",
    "# Dividimos nuestro conjunto de datos en dos subconjuntos separados e independientes:\n",
    "# 1. Conjunto de Entrenamiento (Training Set): Se utiliza para \"enseñar\" o \"ajustar\" el modelo.\n",
    "#    El modelo aprenderá los patrones y relaciones a partir de estos datos.\n",
    "# 2. Conjunto de Prueba (Test Set): Se utiliza para evaluar el rendimiento del modelo una vez entrenado.\n",
    "#    Estos datos son \"nuevos\" para el modelo (no los ha visto durante el entrenamiento),\n",
    "#    lo que nos da una medida más realista de cómo generalizará a datos futuros.\n",
    "\n",
    "# from sklearn.model_selection import train_test_split # Ya importado globalmente.\n",
    "# pandas y numpy también.\n",
    "\n",
    "if 'df' in locals() and not df.empty:\n",
    "    print(\"--- Preprocesamiento: División de Datos en Conjuntos de Entrenamiento y Prueba ---\")\n",
    "\n",
    "    # Identificar la columna objetivo codificada (debería ser algo como 'diagnosis_malignant' de la Celda 11).\n",
    "    encoded_target_col_name_split = None\n",
    "    potential_encoded_targets = [col for col in df.columns if 'diagnosis_' in col and df[col].nunique() == 2]\n",
    "    if potential_encoded_targets:\n",
    "        encoded_target_col_name_split = potential_encoded_targets[0] # Tomamos la primera que coincida\n",
    "    else:\n",
    "        # Intento de rescate si el nombre no es el esperado\n",
    "        for col_candidate in ['target_is_malignant', 'target', 'label', 'class', 'status_encoded', 'output']:\n",
    "            if col_candidate in df.columns and df[col_candidate].nunique() == 2 and pd.api.types.is_numeric_dtype(df[col_candidate]):\n",
    "                encoded_target_col_name_split = col_candidate\n",
    "                break\n",
    "        if not encoded_target_col_name_split and df.iloc[:, -1].nunique() == 2 and pd.api.types.is_numeric_dtype(df.iloc[:, -1]):\n",
    "            encoded_target_col_name_split = df.columns[-1]\n",
    "            print(f\"Advertencia: No se encontró un nombre esperado para el objetivo codificado, usando la última columna numérica binaria: '{encoded_target_col_name_split}'.\")\n",
    "\n",
    "\n",
    "    if encoded_target_col_name_split and encoded_target_col_name_split in df.columns:\n",
    "        print(f\"La variable objetivo para la división será: '{encoded_target_col_name_split}'\")\n",
    "\n",
    "        # Separamos las características predictoras (X) de la variable objetivo (y).\n",
    "        X = df.drop(encoded_target_col_name_split, axis=1)\n",
    "        y = df[encoded_target_col_name_split]\n",
    "\n",
    "        print(f\"\\nDimensiones de X (características predictoras): {X.shape}\")\n",
    "        print(f\"Dimensiones de y (variable objetivo): {y.shape}\")\n",
    "\n",
    "        # Verificamos la distribución de la variable objetivo antes de la división.\n",
    "        print(f\"\\nDistribución de '{encoded_target_col_name_split}' en el conjunto completo (y):\")\n",
    "        print(y.value_counts(normalize=True) * 100)\n",
    "        \n",
    "        # Verificamos que todas las columnas en X sean numéricas.\n",
    "        # El dataset load_breast_cancer ya tiene todas las features numéricas.\n",
    "        non_numeric_features_in_X = X.select_dtypes(exclude=np.number).columns\n",
    "        if not non_numeric_features_in_X.empty:\n",
    "            print(f\"\\n¡Atención! Se encontraron columnas no numéricas en X: {non_numeric_features_in_X.tolist()}\")\n",
    "            print(\"Estas columnas deben ser codificadas o eliminadas antes de entrenar la mayoría de los modelos.\")\n",
    "            # Aquí se podría añadir lógica para codificar estas columnas si fuera un dataset diferente.\n",
    "            # Para este proyecto, no debería ocurrir.\n",
    "        else:\n",
    "            print(\"\\nConfirmado: Todas las características en X son numéricas.\")\n",
    "\n",
    "\n",
    "        # Realizamos la división.\n",
    "        # test_size=0.25: Reservamos el 25% de los datos para el conjunto de prueba.\n",
    "        # random_state=42: Semilla para la aleatoriedad, asegura que la división sea la misma cada vez que se ejecuta.\n",
    "        # stratify=y: ¡Muy importante! Asegura que la proporción de clases en 'y' (0s y 1s)\n",
    "        #              se mantenga aproximadamente igual tanto en el conjunto de entrenamiento como en el de prueba.\n",
    "        #              Esto es crucial si hay desequilibrio de clases.\n",
    "        print(\"\\nRealizando la división en entrenamiento (75%) y prueba (25%)...\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, \n",
    "            test_size=0.25, \n",
    "            random_state=42, \n",
    "            stratify=y\n",
    "        )\n",
    "\n",
    "        print(\"\\n¡División completada!\")\n",
    "        print(f\"  Dimensiones de X_train (entrenamiento): {X_train.shape}\")\n",
    "        print(f\"  Dimensiones de X_test (prueba): {X_test.shape}\")\n",
    "        print(f\"  Dimensiones de y_train (objetivo entrenamiento): {y_train.shape}\")\n",
    "        print(f\"  Dimensiones de y_test (objetivo prueba): {y_test.shape}\")\n",
    "\n",
    "        # Verificamos la estratificación.\n",
    "        print(f\"\\nDistribución de '{encoded_target_col_name_split}' en y_train (entrenamiento):\")\n",
    "        print(y_train.value_counts(normalize=True) * 100)\n",
    "        print(f\"\\nDistribución de '{encoded_target_col_name_split}' en y_test (prueba):\")\n",
    "        print(y_test.value_counts(normalize=True) * 100)\n",
    "        if abs((y_train.value_counts(normalize=True) - y_test.value_counts(normalize=True)).max()) < 0.02: # Pequeña tolerancia\n",
    "             print(\"Confirmado: Las proporciones de la variable objetivo son similares en ambos conjuntos gracias a 'stratify=y'.\")\n",
    "        else:\n",
    "             print(\"Advertencia: Las proporciones del objetivo difieren un poco entre train/test a pesar de stratify. Revisar.\")\n",
    "\n",
    "\n",
    "        # Última revisión: la escala de las características en X_train.\n",
    "        # Esto nos dará una pista para el siguiente paso (escalado).\n",
    "        print(\"\\nAnálisis preliminar de la escala de algunas características en X_train:\")\n",
    "        numeric_cols_in_X_train_check = X_train.select_dtypes(include=np.number).columns\n",
    "        if not numeric_cols_in_X_train_check.empty:\n",
    "            sample_cols_for_scale_check = np.random.choice(\n",
    "                numeric_cols_in_X_train_check, \n",
    "                min(5, len(numeric_cols_in_X_train_check)), # Muestra hasta 5 columnas\n",
    "                replace=False\n",
    "            )\n",
    "            display(X_train[sample_cols_for_scale_check].describe().T[['min', 'max', 'mean', 'std']])\n",
    "            \n",
    "            # Comprobación simple de rangos amplios.\n",
    "            feature_ranges_X_train = X_train[numeric_cols_in_X_train_check].max() - X_train[numeric_cols_in_X_train_check].min()\n",
    "            if (feature_ranges_X_train > 100).any() or (X_train[numeric_cols_in_X_train_check].std() > 50).any():\n",
    "                print(\"\\nObservación importante: Se detecta una variación significativa en las escalas (rangos/desviaciones estándar) de las características.\")\n",
    "                print(\"Es altamente recomendable aplicar escalado (estandarización o normalización) a X_train y X_test.\")\n",
    "            else:\n",
    "                print(\"\\nLas escalas de las características parecen estar en un rango razonable, aunque el escalado suele ser beneficioso.\")\n",
    "        else:\n",
    "            print(\"\\nNo se encontraron características numéricas en X_train para analizar su escala.\")\n",
    "    else:\n",
    "        print(\"\\nError: No se pudo identificar la columna objetivo codificada para realizar la división.\")\n",
    "        print(f\"Columnas disponibles en el DataFrame: {df.columns.tolist()}\")\n",
    "else:\n",
    "    print(\"El DataFrame `df` está vacío o no definido. No se puede proceder con la división de datos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5e43f6-dc16-4f05-8cc0-423b5c0b829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESAMIENTO - ESCALADO DE CARACTERÍSTICAS (ESTANDARIZACIÓN)\n",
    "# -----------------------------------------------------------------------\n",
    "# Como se observó en la celda anterior, las características numéricas tienen diferentes rangos.\n",
    "# El escalado es importante para modelos sensibles a la magnitud de las características (e.g., SVM, Regresión Logística, KNN).\n",
    "# Usaremos StandardScaler para estandarizar las características (media 0, desviación estándar 1).\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd # Asegurarse de que pandas esté disponible\n",
    "\n",
    "if 'X_train' in locals() and 'X_test' in locals():\n",
    "    print(\"--- Escalado de Características (Estandarización) ---\")\n",
    "\n",
    "    # Verificar que X_train y X_test no están vacíos y son DataFrames\n",
    "    if not X_train.empty and not X_test.empty:\n",
    "        \n",
    "        # Crear el objeto StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # Obtener los nombres de las columnas de X_train (asumiendo que son todas numéricas en este punto)\n",
    "        # Si hubo codificación OHE en la celda 12 y se mezclaron con numéricas, esto debería funcionar.\n",
    "        # Dado el output de la celda 12, X_train ya es completamente numérico.\n",
    "        \n",
    "        X_train_columns = X_train.columns\n",
    "        X_test_columns = X_test.columns\n",
    "\n",
    "        print(f\"\\nColumnas en X_train antes del escalado: {X_train.shape[1]}\")\n",
    "        print(f\"Columnas en X_test antes del escalado: {X_test.shape[1]}\")\n",
    "\n",
    "        # Ajustar el scaler CON SOLO DATOS DE ENTRENAMIENTO y luego transformar ambos conjuntos\n",
    "        print(\"\\nAjustando StandardScaler con X_train y transformando X_train y X_test...\")\n",
    "        X_train_scaled_np = scaler.fit_transform(X_train)\n",
    "        X_test_scaled_np = scaler.transform(X_test)\n",
    "\n",
    "        # Convertir los arrays de NumPy de vuelta a DataFrames de Pandas\n",
    "        # Es importante mantener los nombres de las columnas y los índices.\n",
    "        X_train_scaled = pd.DataFrame(X_train_scaled_np, columns=X_train_columns, index=X_train.index)\n",
    "        X_test_scaled = pd.DataFrame(X_test_scaled_np, columns=X_test_columns, index=X_test.index)\n",
    "        \n",
    "        print(\"\\nEscalado completado.\")\n",
    "        \n",
    "        print(\"\\n--- Estadísticas Descriptivas de X_train_scaled (primeras 5 columnas) ---\")\n",
    "        # Usar display si estás en un entorno Jupyter/IPython para mejor formato\n",
    "        # De lo contrario, print(X_train_scaled.iloc[:, :5].describe().T[['min', 'max', 'mean', 'std']])\n",
    "        try:\n",
    "            display(X_train_scaled.iloc[:, :5].describe().T[['min', 'max', 'mean', 'std']])\n",
    "        except NameError: # Si display no está definido (ej. script puro de Python)\n",
    "            print(X_train_scaled.iloc[:, :5].describe().T[['min', 'max', 'mean', 'std']])\n",
    "        \n",
    "        print(\"\\n--- Estadísticas Descriptivas de X_test_scaled (primeras 5 columnas) ---\")\n",
    "        try:\n",
    "            display(X_test_scaled.iloc[:, :5].describe().T[['min', 'max', 'mean', 'std']])\n",
    "        except NameError:\n",
    "            print(X_test_scaled.iloc[:, :5].describe().T[['min', 'max', 'mean', 'std']])\n",
    "        \n",
    "        print(\"\\nLas medias deberían ser cercanas a 0 y las desviaciones estándar cercanas a 1 para X_train_scaled.\")\n",
    "        print(\"X_test_scaled se transforma usando el scaler ajustado en X_train, por lo que sus medias/std pueden variar un poco más.\")\n",
    "\n",
    "        # Guardar los dataframes escalados para las siguientes celdas\n",
    "        # Sobrescribimos X_train y X_test con sus versiones escaladas para simplificar las celdas de modelado.\n",
    "        # Si se quisiera comparar modelos con y sin escalado, se deberían usar nombres diferentes.\n",
    "        X_train = X_train_scaled\n",
    "        X_test = X_test_scaled\n",
    "        \n",
    "        print(\"\\nVariables X_train y X_test actualizadas con los datos escalados.\")\n",
    "        \n",
    "    else:\n",
    "        print(\"X_train o X_test están vacíos. No se puede realizar el escalado.\")\n",
    "else:\n",
    "    print(\"Las variables X_train y X_test no están definidas. Ejecuta la celda 12 primero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80c09d4-a386-4c3a-9995-cdadccb786bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENAMIENTO Y EVALUACIÓN - REGRESIÓN LOGÍSTICA\n",
    "# ---------------------------------------------------------\n",
    "# Ahora que los datos están preprocesados (divididos y escalados),\n",
    "# podemos entrenar nuestro primer modelo. Empezaremos con Regresión Logística.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"--- Entrenamiento y Evaluación: Regresión Logística ---\")\n",
    "\n",
    "# Verificar si las variables necesarias existen\n",
    "if 'X_train' in locals() and 'y_train' in locals() and 'X_test' in locals() and 'y_test' in locals():\n",
    "\n",
    "    # 1. Inicializar y entrenar el modelo\n",
    "    # 'liblinear' es un buen solver para datasets pequeños y problemas binarios.\n",
    "    # random_state para reproducibilidad.\n",
    "    log_reg = LogisticRegression(random_state=42, solver='liblinear')\n",
    "    log_reg.fit(X_train, y_train) # X_train ya está escalado de la celda anterior\n",
    "\n",
    "    print(\"\\nModelo Regresión Logística entrenado.\")\n",
    "\n",
    "    # 2. Realizar predicciones en el conjunto de prueba\n",
    "    y_pred_log_reg = log_reg.predict(X_test) # X_test ya está escalado\n",
    "    y_proba_log_reg = log_reg.predict_proba(X_test)[:, 1] # Probabilidades para la clase positiva (Malignant)\n",
    "\n",
    "    # 3. Evaluar el modelo\n",
    "    print(f\"\\nAccuracy en el conjunto de prueba: {accuracy_score(y_test, y_pred_log_reg):.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    # Asumiendo que 0 es Benign (False) y 1 es Malignant (True) después de la codificación de y\n",
    "    # Esto se basa en cómo 'diagnosis_malignant' fue probablemente creado (True para malignant)\n",
    "    # y cómo LabelEncoder usualmente asigna 0 a la primera etiqueta alfabética y 1 a la segunda si no se especifica.\n",
    "    # Si 'diagnosis_malignant' es directamente True/False, esto funciona.\n",
    "    # Si usaste LabelEncoder explícitamente en 'y', puedes usar le.classes_\n",
    "    # En tu caso, `y` es directamente la columna `diagnosis_malignant` que es True/False,\n",
    "    # y train_test_split mantiene estos valores.\n",
    "    target_names_report = ['Benign (False)', 'Malignant (True)']\n",
    "    print(classification_report(y_test, y_pred_log_reg, target_names=target_names_report))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm_log_reg = confusion_matrix(y_test, y_pred_log_reg)\n",
    "    print(cm_log_reg)\n",
    "\n",
    "    # Visualizar la Matriz de Confusión\n",
    "    plt.figure(figsize=(8,6))\n",
    "    # Los display_labels deben coincidir con el orden de las clases en la matriz de confusión (0, 1)\n",
    "    disp_log_reg = ConfusionMatrixDisplay(confusion_matrix=cm_log_reg, display_labels=target_names_report)\n",
    "    disp_log_reg.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "    plt.title('Confusion Matrix - Logistic Regression')\n",
    "    plt.show()\n",
    "\n",
    "    # Calcular y mostrar ROC AUC Score\n",
    "    roc_auc_log_reg = roc_auc_score(y_test, y_proba_log_reg)\n",
    "    print(f\"\\nROC AUC Score: {roc_auc_log_reg:.4f}\")\n",
    "\n",
    "    # Dibujar la Curva ROC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba_log_reg)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc_log_reg:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--') # Línea de referencia (azar)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity/Recall)')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) - Logistic Regression')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Asegúrate de que X_train, y_train, X_test, y y_test estén definidos y sean correctos.\")\n",
    "    print(\"Ejecuta las celdas de preprocesamiento (especialmente división y escalado) primero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617fa8b4-4731-4692-9f9d-182e76158d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENAMIENTO Y EVALUACIÓN - RANDOM FOREST CLASSIFIER\n",
    "# ------------------------------------------------------------\n",
    "# A continuación, probaremos con un modelo basado en ensambles: Random Forest.\n",
    "# Estos modelos suelen ser más robustos y potentes que los modelos lineales simples.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Las métricas y matplotlib.pyplot ya deberían estar importados de la celda anterior,\n",
    "# pero es buena práctica asegurarse o reimportarlos si es una nueva sesión/celda aislada.\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"--- Entrenamiento y Evaluación: Random Forest Classifier ---\")\n",
    "\n",
    "# Verificar si las variables necesarias existen\n",
    "if 'X_train' in locals() and 'y_train' in locals() and 'X_test' in locals() and 'y_test' in locals():\n",
    "\n",
    "    # 1. Inicializar y entrenar el modelo\n",
    "    # n_estimators: número de árboles en el bosque.\n",
    "    # random_state para reproducibilidad.\n",
    "    rf_clf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced_subsample')\n",
    "    rf_clf.fit(X_train, y_train) # X_train ya está escalado\n",
    "\n",
    "    print(\"\\nModelo Random Forest Classifier entrenado.\")\n",
    "\n",
    "    # 2. Realizar predicciones en el conjunto de prueba\n",
    "    y_pred_rf = rf_clf.predict(X_test) # X_test ya está escalado\n",
    "    y_proba_rf = rf_clf.predict_proba(X_test)[:, 1] # Probabilidades para la clase positiva\n",
    "\n",
    "    # 3. Evaluar el modelo\n",
    "    print(f\"\\nAccuracy en el conjunto de prueba: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    target_names_report = ['Benign (False)', 'Malignant (True)'] # Mismos que en LogReg\n",
    "    print(classification_report(y_test, y_pred_rf, target_names=target_names_report))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "    print(cm_rf)\n",
    "\n",
    "    # Visualizar la Matriz de Confusión\n",
    "    plt.figure(figsize=(8,6))\n",
    "    disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=target_names_report)\n",
    "    disp_rf.plot(cmap=plt.cm.Greens, values_format='d') # Diferente color para distinguir\n",
    "    plt.title('Confusion Matrix - Random Forest Classifier')\n",
    "    plt.show()\n",
    "\n",
    "    # Calcular y mostrar ROC AUC Score\n",
    "    roc_auc_rf = roc_auc_score(y_test, y_proba_rf)\n",
    "    print(f\"\\nROC AUC Score: {roc_auc_rf:.4f}\")\n",
    "\n",
    "    # Dibujar la Curva ROC\n",
    "    fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_proba_rf)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(fpr_rf, tpr_rf, color='green', lw=2, label=f'ROC curve (area = {roc_auc_rf:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity/Recall)')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) - Random Forest')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Asegúrate de que X_train, y_train, X_test, y y_test estén definidos y sean correctos.\")\n",
    "    print(\"Ejecuta las celdas de preprocesamiento (especialmente división y escalado) primero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8cf80-d65a-4be5-88cf-ba4add89a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENAMIENTO Y EVALUACIÓN - SUPPORT VECTOR MACHINE (SVC)\n",
    "# -----------------------------------------------------------------\n",
    "# Continuamos explorando modelos, ahora con Support Vector Machines (SVM),\n",
    "# específicamente Support Vector Classifier (SVC) para clasificación.\n",
    "# Los SVM pueden ser muy efectivos, especialmente en espacios de alta dimensión.\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "# Las métricas y matplotlib.pyplot ya deberían estar importados.\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"--- Entrenamiento y Evaluación: Support Vector Machine (SVC) ---\")\n",
    "\n",
    "# Verificar si las variables necesarias existen\n",
    "if 'X_train' in locals() and 'y_train' in locals() and 'X_test' in locals() and 'y_test' in locals():\n",
    "\n",
    "    # 1. Inicializar y entrenar el modelo\n",
    "    # probability=True es necesario para poder usar predict_proba y calcular ROC AUC.\n",
    "    # Puede hacer que el entrenamiento sea un poco más lento.\n",
    "    # random_state para reproducibilidad si el SVC tiene algún componente estocástico (menos común).\n",
    "    # C es el parámetro de regularización. Un valor más alto significa menos regularización.\n",
    "    # kernel='rbf' (Radial Basis Function) es una elección común y potente.\n",
    "    svc_clf = SVC(probability=True, random_state=42, C=1.0, kernel='rbf', class_weight='balanced')\n",
    "    svc_clf.fit(X_train, y_train) # X_train ya está escalado\n",
    "\n",
    "    print(\"\\nModelo Support Vector Machine (SVC) entrenado.\")\n",
    "\n",
    "    # 2. Realizar predicciones en el conjunto de prueba\n",
    "    y_pred_svc = svc_clf.predict(X_test) # X_test ya está escalado\n",
    "    y_proba_svc = svc_clf.predict_proba(X_test)[:, 1] # Probabilidades para la clase positiva\n",
    "\n",
    "    # 3. Evaluar el modelo\n",
    "    print(f\"\\nAccuracy en el conjunto de prueba: {accuracy_score(y_test, y_pred_svc):.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    target_names_report = ['Benign (False)', 'Malignant (True)'] # Mismos que antes\n",
    "    print(classification_report(y_test, y_pred_svc, target_names=target_names_report))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm_svc = confusion_matrix(y_test, y_pred_svc)\n",
    "    print(cm_svc)\n",
    "\n",
    "    # Visualizar la Matriz de Confusión\n",
    "    plt.figure(figsize=(8,6))\n",
    "    disp_svc = ConfusionMatrixDisplay(confusion_matrix=cm_svc, display_labels=target_names_report)\n",
    "    disp_svc.plot(cmap=plt.cm.Oranges, values_format='d') # Diferente color\n",
    "    plt.title('Confusion Matrix - Support Vector Machine (SVC)')\n",
    "    plt.show()\n",
    "\n",
    "    # Calcular y mostrar ROC AUC Score\n",
    "    roc_auc_svc = roc_auc_score(y_test, y_proba_svc)\n",
    "    print(f\"\\nROC AUC Score: {roc_auc_svc:.4f}\")\n",
    "\n",
    "    # Dibujar la Curva ROC\n",
    "    fpr_svc, tpr_svc, thresholds_svc = roc_curve(y_test, y_proba_svc)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(fpr_svc, tpr_svc, color='orange', lw=2, label=f'ROC curve (area = {roc_auc_svc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity/Recall)')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) - SVC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Asegúrate de que X_train, y_train, X_test, y y_test estén definidos y sean correctos.\")\n",
    "    print(\"Ejecuta las celdas de preprocesamiento (especialmente división y escalado) primero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b96572-9e3e-4f40-a3cd-7f81eeb8eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENAMIENTO Y EVALUACIÓN - XGBOOST CLASSIFIER\n",
    "# -------------------------------------------------------\n",
    "# Finalmente, probaremos con XGBoost, un algoritmo de Gradient Boosting\n",
    "# muy popular y eficiente, conocido por su alto rendimiento.\n",
    "\n",
    "import xgboost as xgb\n",
    "# Las métricas y matplotlib.pyplot ya deberían estar importados.\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"--- Entrenamiento y Evaluación: XGBoost Classifier ---\")\n",
    "\n",
    "# Verificar si las variables necesarias existen\n",
    "if 'X_train' in locals() and 'y_train' in locals() and 'X_test' in locals() and 'y_test' in locals():\n",
    "\n",
    "    # 1. Inicializar y entrenar el modelo\n",
    "    # random_state para reproducibilidad.\n",
    "    # use_label_encoder=False para evitar una advertencia común con versiones recientes de XGBoost.\n",
    "    # eval_metric='logloss' es una métrica de evaluación común para clasificación binaria durante el entrenamiento (si se usa early stopping).\n",
    "    # n_estimators: número de árboles (rondas de boosting).\n",
    "    # learning_rate: reduce la contribución de cada árbol.\n",
    "    # max_depth: profundidad máxima de cada árbol.\n",
    "    # scale_pos_weight: útil para clases desbalanceadas. Se calcula como (count(negative_class) / count(positive_class)).\n",
    "    # Contemos las clases en y_train para scale_pos_weight\n",
    "    count_benign_train = (y_train == 0).sum() # Asumiendo 0 para benigno (False)\n",
    "    count_malignant_train = (y_train == 1).sum() # Asumiendo 1 para maligno (True)\n",
    "    \n",
    "    scale_pos_weight_xgb = 1 # Valor por defecto si algo falla\n",
    "    if count_malignant_train > 0: # Evitar división por cero\n",
    "        scale_pos_weight_xgb = count_benign_train / count_malignant_train\n",
    "    print(f\"Calculado scale_pos_weight para XGBoost: {scale_pos_weight_xgb:.2f}\")\n",
    "\n",
    "    xgb_clf = xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3, # Profundidad típica para empezar\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=scale_pos_weight_xgb # Para manejar desequilibrio\n",
    "    )\n",
    "    xgb_clf.fit(X_train, y_train) # X_train ya está escalado\n",
    "\n",
    "    print(\"\\nModelo XGBoost Classifier entrenado.\")\n",
    "\n",
    "    # 2. Realizar predicciones en el conjunto de prueba\n",
    "    y_pred_xgb = xgb_clf.predict(X_test) # X_test ya está escalado\n",
    "    y_proba_xgb = xgb_clf.predict_proba(X_test)[:, 1] # Probabilidades para la clase positiva\n",
    "\n",
    "    # 3. Evaluar el modelo\n",
    "    print(f\"\\nAccuracy en el conjunto de prueba: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    target_names_report = ['Benign (False)', 'Malignant (True)'] # Mismos que antes\n",
    "    print(classification_report(y_test, y_pred_xgb, target_names=target_names_report))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "    print(cm_xgb)\n",
    "\n",
    "    # Visualizar la Matriz de Confusión\n",
    "    plt.figure(figsize=(8,6))\n",
    "    disp_xgb = ConfusionMatrixDisplay(confusion_matrix=cm_xgb, display_labels=target_names_report)\n",
    "    disp_xgb.plot(cmap=plt.cm.Purples, values_format='d') # Diferente color\n",
    "    plt.title('Confusion Matrix - XGBoost Classifier')\n",
    "    plt.show()\n",
    "\n",
    "    # Calcular y mostrar ROC AUC Score\n",
    "    roc_auc_xgb = roc_auc_score(y_test, y_proba_xgb)\n",
    "    print(f\"\\nROC AUC Score: {roc_auc_xgb:.4f}\")\n",
    "\n",
    "    # Dibujar la Curva ROC\n",
    "    fpr_xgb, tpr_xgb, thresholds_xgb = roc_curve(y_test, y_proba_xgb)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(fpr_xgb, tpr_xgb, color='purple', lw=2, label=f'ROC curve (area = {roc_auc_xgb:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity/Recall)')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) - XGBoost')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Asegúrate de que X_train, y_train, X_test, y y_test estén definidos y sean correctos.\")\n",
    "    print(\"Ejecuta las celdas de preprocesamiento (especialmente división y escalado) primero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af6ab0-1976-4595-a9ec-2617d1323d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARACIÓN DE MODELOS\n",
    "# ------------------------------\n",
    "# Ahora que hemos entrenado y evaluado varios modelos,\n",
    "# vamos a comparar sus métricas clave para determinar cuál tuvo el mejor rendimiento.\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # Para np.nan si alguna variable no estuviera definida\n",
    "\n",
    "print(\"--- Comparación de Modelos ---\")\n",
    "\n",
    "# Asegurarse de que todas las variables de predicción y ROC AUC estén disponibles.\n",
    "# Usaremos try-except para manejar el caso de que alguna no se haya ejecutado.\n",
    "\n",
    "model_data = []\n",
    "\n",
    "try:\n",
    "    model_data.append({\n",
    "        'Model': 'Logistic Regression',\n",
    "        'Accuracy': accuracy_score(y_test, y_pred_log_reg),\n",
    "        'ROC AUC Score': roc_auc_log_reg,\n",
    "        'FN': confusion_matrix(y_test, y_pred_log_reg)[1, 0], # Fila 1, Columna 0 para FN\n",
    "        'FP': confusion_matrix(y_test, y_pred_log_reg)[0, 1]  # Fila 0, Columna 1 para FP\n",
    "    })\n",
    "except NameError:\n",
    "    print(\"Advertencia: Resultados de Regresión Logística no encontrados.\")\n",
    "    model_data.append({'Model': 'Logistic Regression', 'Accuracy': np.nan, 'ROC AUC Score': np.nan, 'FN': np.nan, 'FP': np.nan})\n",
    "\n",
    "try:\n",
    "    model_data.append({\n",
    "        'Model': 'Random Forest',\n",
    "        'Accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "        'ROC AUC Score': roc_auc_rf,\n",
    "        'FN': confusion_matrix(y_test, y_pred_rf)[1, 0],\n",
    "        'FP': confusion_matrix(y_test, y_pred_rf)[0, 1]\n",
    "    })\n",
    "except NameError:\n",
    "    print(\"Advertencia: Resultados de Random Forest no encontrados.\")\n",
    "    model_data.append({'Model': 'Random Forest', 'Accuracy': np.nan, 'ROC AUC Score': np.nan, 'FN': np.nan, 'FP': np.nan})\n",
    "\n",
    "try:\n",
    "    model_data.append({\n",
    "        'Model': 'SVC',\n",
    "        'Accuracy': accuracy_score(y_test, y_pred_svc),\n",
    "        'ROC AUC Score': roc_auc_svc,\n",
    "        'FN': confusion_matrix(y_test, y_pred_svc)[1, 0],\n",
    "        'FP': confusion_matrix(y_test, y_pred_svc)[0, 1]\n",
    "    })\n",
    "except NameError:\n",
    "    print(\"Advertencia: Resultados de SVC no encontrados.\")\n",
    "    model_data.append({'Model': 'SVC', 'Accuracy': np.nan, 'ROC AUC Score': np.nan, 'FN': np.nan, 'FP': np.nan})\n",
    "\n",
    "try:\n",
    "    model_data.append({\n",
    "        'Model': 'XGBoost',\n",
    "        'Accuracy': accuracy_score(y_test, y_pred_xgb),\n",
    "        'ROC AUC Score': roc_auc_xgb,\n",
    "        'FN': confusion_matrix(y_test, y_pred_xgb)[1, 0],\n",
    "        'FP': confusion_matrix(y_test, y_pred_xgb)[0, 1]\n",
    "    })\n",
    "except NameError:\n",
    "    print(\"Advertencia: Resultados de XGBoost no encontrados.\")\n",
    "    model_data.append({'Model': 'XGBoost', 'Accuracy': np.nan, 'ROC AUC Score': np.nan, 'FN': np.nan, 'FP': np.nan})\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(model_data)\n",
    "# Ordenar por FN (ascendente, menos es mejor) y luego por ROC AUC (descendente) como desempate\n",
    "results_df = results_df.sort_values(by=['FN', 'ROC AUC Score'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nResultados de los Modelos (Ordenados por FN y luego ROC AUC):\")\n",
    "# Usar display si estás en un entorno Jupyter/IPython para mejor formato\n",
    "try:\n",
    "    display(results_df)\n",
    "except NameError:\n",
    "    print(results_df)\n",
    "\n",
    "# --- Visualizaciones de Comparación ---\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid') # Asegurar estilo consistente\n",
    "\n",
    "# Comparación de Accuracy\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax_acc = sns.barplot(x='Accuracy', y='Model', data=results_df.sort_values(by='Accuracy', ascending=False), palette='viridis', orient='h')\n",
    "plt.title('Comparación de Accuracy de Modelos', fontsize=16)\n",
    "plt.xlabel('Accuracy', fontsize=14)\n",
    "plt.ylabel('Modelo', fontsize=14)\n",
    "plt.xlim(0.90, 1.005) # Ajustar límites para mejor visualización\n",
    "for i in ax_acc.containers:\n",
    "    ax_acc.bar_label(i, fmt='%.4f', padding=3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparación de ROC AUC Score\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax_roc = sns.barplot(x='ROC AUC Score', y='Model', data=results_df.sort_values(by='ROC AUC Score', ascending=False), palette='magma', orient='h')\n",
    "plt.title('Comparación de ROC AUC Score de Modelos', fontsize=16)\n",
    "plt.xlabel('ROC AUC Score', fontsize=14)\n",
    "plt.ylabel('Modelo', fontsize=14)\n",
    "plt.xlim(0.98, 1.005) # Ajustar límites\n",
    "for i in ax_roc.containers:\n",
    "    ax_roc.bar_label(i, fmt='%.4f', padding=3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparación de Falsos Negativos (FN)\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax_fn = sns.barplot(x='FN', y='Model', data=results_df.sort_values(by='FN', ascending=True), palette='coolwarm', orient='h')\n",
    "plt.title('Comparación de Falsos Negativos (FN) de Modelos', fontsize=16)\n",
    "plt.xlabel('Número de Falsos Negativos', fontsize=14)\n",
    "plt.ylabel('Modelo', fontsize=14)\n",
    "# Ajustar límites, puede ser de 0 a un poco más del máximo FN\n",
    "max_fn = results_df['FN'].max()\n",
    "plt.xlim(-0.5, max_fn + 1 if not pd.isna(max_fn) else 5)\n",
    "for i in ax_fn.containers:\n",
    "    ax_fn.bar_label(i, fmt='%d', padding=3) # Formato entero para FN\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparación de Falsos Positivos (FP)\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax_fp = sns.barplot(x='FP', y='Model', data=results_df.sort_values(by='FP', ascending=True), palette='Spectral', orient='h')\n",
    "plt.title('Comparación de Falsos Positivos (FP) de Modelos', fontsize=16)\n",
    "plt.xlabel('Número de Falsos Positivos', fontsize=14)\n",
    "plt.ylabel('Modelo', fontsize=14)\n",
    "max_fp = results_df['FP'].max()\n",
    "plt.xlim(-0.5, max_fp + 1 if not pd.isna(max_fp) else 2)\n",
    "for i in ax_fp.containers:\n",
    "    ax_fp.bar_label(i, fmt='%d', padding=3) # Formato entero para FP\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Conclusión Preliminar ---\n",
    "print(\"\\n--- Conclusión Preliminar ---\")\n",
    "if not results_df.empty and not results_df['FN'].isnull().all():\n",
    "    best_overall_model = results_df.iloc[0] # El primero después de ordenar\n",
    "    print(f\"Considerando la prioridad de minimizar Falsos Negativos (FN) y luego maximizar ROC AUC:\")\n",
    "    print(f\"El modelo más prometedor es **{best_overall_model['Model']}** con:\")\n",
    "    print(f\"  - Falsos Negativos (FN): {best_overall_model['FN']:.0f}\")\n",
    "    print(f\"  - Falsos Positivos (FP): {best_overall_model['FP']:.0f}\")\n",
    "    print(f\"  - Accuracy: {best_overall_model['Accuracy']:.4f}\")\n",
    "    print(f\"  - ROC AUC Score: {best_overall_model['ROC AUC Score']:.4f}\")\n",
    "\n",
    "    print(\"\\nTodos los modelos han mostrado un rendimiento general muy alto en este dataset.\")\n",
    "    print(\"La elección final del 'mejor' modelo a menudo depende del costo relativo de los diferentes tipos de errores en el contexto específico del problema.\")\n",
    "    print(\"Para el diagnóstico de cáncer, minimizar los Falsos Negativos (no detectar un caso maligno) suele ser la máxima prioridad.\")\n",
    "else:\n",
    "    print(\"No se pudieron recopilar suficientes datos para una conclusión.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef104b08-e535-4424-afea-698a2c2c152e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
